{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UA4zTjvOF1uy","executionInfo":{"status":"ok","timestamp":1710152267642,"user_tz":-330,"elapsed":26358,"user":{"displayName":"Animesh Sharma","userId":"02623856243471437998"}},"outputId":"4002917e-6087-4b0b-b53b-73de3cc1da7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install -U transformers\n","!pip install bitsandbytes\n","!pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1EIC0Z5TxIjW"},"outputs":[],"source":["dir = \"drive/MyDrive/state\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfwKiBnuE3hi","executionInfo":{"status":"ok","timestamp":1710152270310,"user_tz":-330,"elapsed":2678,"user":{"displayName":"Animesh Sharma","userId":"02623856243471437998"}},"outputId":"621452c8-1427-4edf-a7f2-219243807d7b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}],"source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbl5Bj4P8RF1"},"outputs":[],"source":["import os\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQah60w-trNX"},"outputs":[],"source":["class Model:\n","    def __init__(self, model_name=\"mistral\"):\n","        self.model_name = model_name\n","        self.tokenizer = None\n","        self.model = None\n","\n","        # define configuration for quantization\n","        # useful for low memory requirement\n","        self.bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=(model_name == \"mixtral\"), # store the model's information in tiny 4-bit pieces instead of the usual 32-bit chunks\n","            load_in_8bit=(model_name == \"mistral\"), # store the model's information in tiny 8-bit pieces\n","            bnb_4bit_compute_dtype=torch.float16 # do calculations using a slightly smaller data format called \"float16\" instead of the usual \"float32\"\n","        )\n","\n","        if model_name == \"mistral\":\n","            self.get_mistral_model()\n","        else:\n","            self.get_mixtral_model()\n","\n","    def get_mistral_model(self):\n","        model_name = \"mistralai/Mistral-7B-v0.1\"\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=os.path.join(dir, \"mistral_data\"))\n","        self.model = AutoModelForCausalLM.from_pretrained(\n","            model_name,\n","            quantization_config=self.bnb_config,\n","            device_map=\"auto\",\n","            cache_dir=os.path.join(dir, \"mistral_data\")\n","        )\n","\n","    def get_mixtral_model(self):\n","        model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=os.path.join(dir, \"mixtral_data\"))\n","        self.model = AutoModelForCausalLM.from_pretrained(\n","            model_name,\n","            quantization_config=self.bnb_config,\n","            device_map=\"auto\",\n","            cache_dir=os.path.join(dir, \"mixtral_data\")\n","        )\n","\n","    def generate(self, prompt):\n","        input = self.tokenizer(prompt, return_tensors=\"pt\").to(device)\n","        output = self.model.generate(**input, max_new_tokens=50)\n","\n","        return self.tokenizer.decode(output[0], skip_special_tokens=(self.model_name == \"mixtral\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9l65ZM6xEN_"},"outputs":[],"source":["import re"]},{"cell_type":"code","source":["def get_state(output, words):\n","    temp = output.lower().split(words)[-1]\n","    lines = temp.split(\"\\n\")\n","    state = \"\"\n","\n","    for line in lines:\n","        if any(keyword in line for keyword in [\"thought\", \"feeling\", \"action\", \"other\"]):\n","            state += \"\\n\" + line\n","\n","            if \"other\" in line:\n","                break\n","\n","    return state"],"metadata":{"id":"AE88_0k5uH_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zn0Sifw09CZK"},"outputs":[],"source":["def get_categories(output, words):\n","    categories = dict.fromkeys(['thought', 'feeling', 'action', 'other'], [])\n","    state = get_state(output, words)\n","    temp = re.split(r\"\\s?(thought|feeling|action|other)s?\\W{2,}\", state)\n","\n","    for i in range(len(temp)):\n","        if any(keyword in temp[i] for keyword in [\"thought\", \"feeling\", \"action\", \"other\"]):\n","            categories[temp[i]] = [] if temp[i + 1] == 'none' else re.split(r\"\\s*,\\s*\", temp[i + 1].rstrip(\"\\n\"))\n","\n","    return categories, state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwWVk6FgDIUz"},"outputs":[],"source":["def get_sentence(output, state, start_datetime, end_datetime):\n","    temp = re.split(state, output, re.IGNORECASE)[-1]\n","    lines = temp.split(\"\\n\")\n","\n","    for line in lines:\n","        if \"output\" in line or \"Output\" in line:\n","            sentence = re.sub(r\"[oO]utput\\W+\", '', line)\n","\n","            return f\"{start_datetime}, \" + (f\"{end_datetime}, \" if end_datetime else '') + sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUg7inFjC8O7"},"outputs":[],"source":["from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ceL6Mf6--R_K"},"outputs":[],"source":["class Task(Model):\n","    def __init__(self, model_name=\"mistral\"):\n","        super().__init__(model_name)\n","        self.start_datetime = ''\n","        self.end_datetime = ''\n","        self.state = None\n","\n","    def semantic_classification(self, words, start_datetime='', end_datetime=''):\n","        self.start_datetime = start_datetime if start_datetime else datetime.now().strftime(\"%H:%M %d/%m/%Y\")\n","        self.end_datetime = end_datetime\n","\n","        prompt = \"\"\"You will be given a list of unordered words that describe various aspects of a person's state in their daily life. Your first objective is to review the words and connect them into coherent phrases that accurately represent daily life activities or states. Once you have identified potential phrases, categorize each phrase and any remaining individual words STRICTLY into ONE of the following categories with a focus on daily life context: \"Thoughts,\" \"Feelings,\" \"Actions,\" or \"Others.\" Follow these contextual guidelines:\n","\n","1. Phrase Formation in Daily Life Context:\n","Look for connections between words that naturally fit together to describe daily life scenarios, states, or activities.\n","Create phrases that reflect these daily life experiences before categorization.\n","\n","2. Categories Defined with Daily Life Focus:\n","Thoughts: Cognitive states or mental activities related to daily life.\n","Feelings: Emotions or moods one may experience throughout the day.\n","Actions: Physical activities or tasks are done as part of a routine.\n","Others: Words or phrases that do not represent thoughts, feelings, or actions in the context of daily life.\n","\n","3. Categorizing with Context:\n","Determine the best category for each word or phrase, grounded in the context of an individual's day-to-day experience.\n","\n","4. Contextual Examples:\n","Given \"morning,\" \"refreshed,\" and \"yoga,\" create a phrase reflecting a morning routine, then categorize:\n","\"refreshed\" captures a feeling, categorized under \"Feelings.\"\n","\"morning yoga\" is a daily activity, so it belongs in \"Actions.\"\n","\n","5. Ambiguity and Contextual Judgement:\n","For ambiguous situations, consider the context of daily life to guide the categorization; otherwise, use the \"Others\" category.\n","\n","For Example:\n","\n","1. Input: water, joy, plant, weeds, think, summer\n","Output:\n","Thoughts: think\n","Feelings: joy\n","Actions: water plants, remove weeds\n","Others: summer\n","\n","2. Input: deadline, teamwork, report, finalize, schedule, results, feedback, analyze, implement, coordinate\n","Output:\n","Thoughts: analyze results\n","Feelings: none\n","Actions: finalize report by deadline, schedule and coordinate teamwork, and feedback to implement\n","Others: none\n","\n","Based on the above provided explanation and examples find the categories for the following without creating any additional examples:\n","\n","Input: {}\n","Output:\"\"\".format(words)\n","        categories, self.state = get_categories(self.generate(prompt), words)\n","\n","        return categories\n","\n","    def sent_generation(self):\n","        prompt = \"\"\"Imagine you have a snapshot of a person's past moment, encompassing all the elements from their experience, which comprises their \"thoughts\", \"feelings\", \"actions\", and \"environment/surroundings (others)\". Your task is to weave together these elements into a single, coherent sentence in the past continuous tense. This sentence should reflect the essence of the moment, conveying the atmosphere and the emotions present. It is vital to include every provided category in your sentence to ensure a complete and vivid depiction of the scene. Your ability to understand nuanced human behavior and context should help you craft a sentence that is both engaging and true to life.\n","\n","Input:\n","thoughts: reminiscing about childhood\n","feelings: nostalgic, content\n","actions: none\n","others: none\n","Output: You were feeling nostalgic and content, reminiscing about your childhood.\n","\n","Input:\n","thoughts: outlining a presentation\n","feelings: focused, calm\n","actions: creating slides\n","others: soft jazz music, dim desk lamp\n","Output: Calmly focused, you were outlining a presentation, creating slides under dim light with jazz music softly playing.\n","\n","Based on the above-provided explanation and examples create the sentence for the following without creating any additional examples:\n","\n","Input:{}\n","Output:\"\"\".format(self.state)\n","\n","        return get_sentence(self.generate(prompt), self.state, self.start_datetime, self.end_datetime)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"se-NOiMeDBor"},"outputs":[],"source":["from pprint import pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cz_91dgv-Oww"},"outputs":[],"source":["words = \"happy, cheese, lunch\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyudQn0XRPPZ","colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["d1ed63dcd3f749a5b48dadd4f8e9a160","95d8f1b922894d8ab5e82be3536b0623","d1e7859681f34bd59d6197597715930c","a7df0cdfebf94e66864aaf45257aef9f","bb7d76d0bc3041609bb8e2cb9ddc8295","2e06d0c2e71848e6a8a1870cbbbf7473","c2fe7e5213964798a7a8c68b9ac74820","af27c2fd93ea481e95033aaccc4ca55c","3ed4ec3cf1534da8aa61596d967b0dcd","cabdd4b2c18048d2a8734ac3b3140f27","61d82b6463cc4af489a3b861cce1a8e6"]},"executionInfo":{"status":"ok","timestamp":1710152480885,"user_tz":-330,"elapsed":208323,"user":{"displayName":"Animesh Sharma","userId":"02623856243471437998"}},"outputId":"f3ccb87e-d5b5-427c-c748-e0df4097800e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ed63dcd3f749a5b48dadd4f8e9a160"}},"metadata":{}}],"source":["task = Task(model_name=\"mistral\") # two models: \"mistral\" and \"mixtral\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UroB0a8s5Wfo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710152505087,"user_tz":-330,"elapsed":24218,"user":{"displayName":"Animesh Sharma","userId":"02623856243471437998"}},"outputId":"ea235154-39db-4646-8668-46a69bb6fe80"},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'thought': [],\n"," 'feeling': ['happy'],\n"," 'action': ['eat lunch'],\n"," 'other': ['cheese']}"]},"metadata":{},"execution_count":15}],"source":["task.semantic_classification(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rxxdi0qn_vuG","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"b2ba8118-3f06-4e47-ea51-58014c7fb7ed","executionInfo":{"status":"ok","timestamp":1710152520830,"user_tz":-330,"elapsed":15759,"user":{"displayName":"Animesh Sharma","userId":"02623856243471437998"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["'10:21 11/03/2024, You were happy, eating lunch with cheese.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["task.sent_generation()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1cutQoS2da3-eDXkj9GRJFmVeqgUZ2N-K","authorship_tag":"ABX9TyM5d9RzDhLtt6BPO70Qyi+s"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d1ed63dcd3f749a5b48dadd4f8e9a160":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95d8f1b922894d8ab5e82be3536b0623","IPY_MODEL_d1e7859681f34bd59d6197597715930c","IPY_MODEL_a7df0cdfebf94e66864aaf45257aef9f"],"layout":"IPY_MODEL_bb7d76d0bc3041609bb8e2cb9ddc8295"}},"95d8f1b922894d8ab5e82be3536b0623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e06d0c2e71848e6a8a1870cbbbf7473","placeholder":"​","style":"IPY_MODEL_c2fe7e5213964798a7a8c68b9ac74820","value":"Loading checkpoint shards: 100%"}},"d1e7859681f34bd59d6197597715930c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af27c2fd93ea481e95033aaccc4ca55c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ed4ec3cf1534da8aa61596d967b0dcd","value":2}},"a7df0cdfebf94e66864aaf45257aef9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cabdd4b2c18048d2a8734ac3b3140f27","placeholder":"​","style":"IPY_MODEL_61d82b6463cc4af489a3b861cce1a8e6","value":" 2/2 [03:05&lt;00:00, 80.56s/it]"}},"bb7d76d0bc3041609bb8e2cb9ddc8295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e06d0c2e71848e6a8a1870cbbbf7473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2fe7e5213964798a7a8c68b9ac74820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af27c2fd93ea481e95033aaccc4ca55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed4ec3cf1534da8aa61596d967b0dcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cabdd4b2c18048d2a8734ac3b3140f27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d82b6463cc4af489a3b861cce1a8e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}